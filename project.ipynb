{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TAL - Classification de dépêches d’agence avec NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing modules\n",
    "import nltk\n",
    "import string\n",
    "import collections\n",
    "\n",
    "from nltk.corpus import reuters\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.metrics.scores import (precision, recall, f_measure)\n",
    "\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['NORTH', 'EAST', '&', 'lt', ';', 'NEIC', '>', 'MAY', ...], ['earn'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract fileids from the reuters corpus\n",
    "fileids = reuters.fileids()\n",
    "documents = []\n",
    "# Loop through each file id and collect each files categories and tokenized words\n",
    "for file in fileids:\n",
    "    words = reuters.words(file)\n",
    "    documents.append((words, reuters.categories(file)))\n",
    "\n",
    "shuffle(documents)\n",
    "documents[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons remarqué que dans la tokenisation des mots du corpus, le mots `U.S` est séparé en trois tokens distinct, `U`, `.` et `S`. Nous avon estimé que dans le cadre de ce labo, cela ne devrait pas causer trop de problèmes et nous avons donc laissé cette séparation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifieur binaire\n",
    "\n",
    "Pour la classification des documents, nous avons décidé d'utiliser la fréquence des mots. Nous avons donc commencé par déterminer la fréquence de **TOUT** les mots du dataset (i.e. tout les documents), puis les `2000` mots les plus fréquents sont retourné.\n",
    "\n",
    "> Note: La limite de la fréquence des mots que la fonction retourne est paramètrable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def document_features(document, word_frequence):\n",
    "    document_words = set(document)\n",
    "    features = {}\n",
    "    for word in word_frequence:\n",
    "        features['contains({})'.format(word)] = (word in document_words)\n",
    "    return features\n",
    "\n",
    "def most_freq_words(documents, limit=2000):\n",
    "    all_words = nltk.FreqDist(w\n",
    "        for document in documents\n",
    "        for w in document[0]\n",
    "    )\n",
    "    return list(all_words)[:limit]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(documents, tag, feature_extractor, **kwargs):\n",
    "    if 'to_lower' in kwargs and kwargs['to_lower']:\n",
    "        documents = list(map(lambda d: (list(map(str.lower, d[0])), d[1]), documents))\n",
    "\n",
    "    if 'lemmatizer' in kwargs:\n",
    "        lemmatizer = kwargs['lemmatizer']\n",
    "        documents = list(map(lambda d: (list(map(lemmatizer.lemmatize, d[0])), d[1]), documents))\n",
    "    \n",
    "    if 'stopwords' in kwargs:\n",
    "        stopwords = set(kwargs['stopwords'])\n",
    "        documents = list(map(\n",
    "            lambda d: (\n",
    "                list(filter(lambda w: not w.lower() in stopwords and w[0].isalnum(), d[0])), \n",
    "                d[1]\n",
    "            ), documents))\n",
    "        \n",
    "    analyzer_res = []\n",
    "    if 'analyzer' in kwargs:\n",
    "        analyzer_res = kwargs['analyzer'](documents)\n",
    "\n",
    "    dataset = []\n",
    "    for document in documents:\n",
    "        dataset.append((feature_extractor(document[0], analyzer_res), tag in document[1]))\n",
    "    \n",
    "    shuffle(dataset)\n",
    "    return dataset\n",
    "\n",
    "def split_dataset(dataset):\n",
    "    split_ratio = 0.6\n",
    "    split_ratio2 = 0.8\n",
    "    \n",
    "    split = int(len(dataset) * split_ratio)\n",
    "    split2 = int(len(dataset) * split_ratio2)\n",
    "\n",
    "    return (dataset[:split], dataset[split:split2], dataset[split2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_classifier(documents, tag, dataset_creator, hyperparams):\n",
    "    print('Finding best classifier for {}'.format(tag))\n",
    "    print('----------')\n",
    "\n",
    "    best = (None, 0.0)\n",
    "    for hyperparam in hyperparams:\n",
    "        dataset = dataset_creator(documents, tag, **hyperparam)\n",
    "        train_set, test_set, dev_set = split_dataset(dataset)\n",
    "        classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "        acc = nltk.classify.accuracy(classifier, dev_set)\n",
    "        \n",
    "        if acc > best[1]:\n",
    "            best = (classifier, acc)\n",
    "        \n",
    "        print('Accuracy using \"{}\": {:.2f}%'.format(hyperparam['title'], acc*100))\n",
    "    return (best[0], test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combinaison des différents hyperparamètres\n",
    "\n",
    "TODO explain the hyperparam we're going to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparams = [\n",
    "    {\n",
    "        'title': 'To lower: no, Lemmatize: no, No stopwords: no',\n",
    "        'feature_extractor': document_features,\n",
    "        'analyzer': most_freq_words,\n",
    "    },\n",
    "    {\n",
    "        'title': 'To lower: yes, Lemmatize: no, No stopwords: no',\n",
    "        'feature_extractor': document_features,\n",
    "        'analyzer': most_freq_words,\n",
    "        'to_lower': True,\n",
    "    },\n",
    "    {\n",
    "        'title': 'To lower: no, Lemmatize: yes, No stopwords: no',\n",
    "        'feature_extractor': document_features,\n",
    "        'analyzer': most_freq_words,\n",
    "        'lemmatizer': WordNetLemmatizer(),\n",
    "    },\n",
    "    {\n",
    "        'title': 'To lower: no, Lemmatize: no, No stopwords: yes',\n",
    "        'feature_extractor': document_features,\n",
    "        'analyzer': most_freq_words,\n",
    "        'stopwords': stopwords.words('english'),\n",
    "    },\n",
    "    {\n",
    "        'title': 'To lower: yes, Lemmatize: no, No stopwords: yes',\n",
    "        'feature_extractor': document_features,\n",
    "        'analyzer': most_freq_words,\n",
    "        'to_lower': True,\n",
    "        'stopwords': stopwords.words('english'),\n",
    "    },\n",
    "    {\n",
    "        'title': 'To lower: no, Lemmatize: yes, No stopwords: yes',\n",
    "        'feature_extractor': document_features,\n",
    "        'analyzer': most_freq_words,\n",
    "        'lemmatizer': WordNetLemmatizer(),\n",
    "        'stopwords': stopwords.words('english'),\n",
    "    },\n",
    "    {\n",
    "        'title': 'To lower: yes, Lemmatize: yes, No stopwords: no',\n",
    "        'feature_extractor': document_features,\n",
    "        'analyzer': most_freq_words,\n",
    "        'to_lower': True,\n",
    "        'lemmatizer': WordNetLemmatizer(),\n",
    "    },\n",
    "    {\n",
    "        'title': 'To lower: yes, Lemmatize: yes, No stopwords: yes',\n",
    "        'feature_extractor': document_features,\n",
    "        'analyzer': most_freq_words,\n",
    "        'to_lower': True,\n",
    "        'stopwords': stopwords.words('english'),\n",
    "        'lemmatizer': WordNetLemmatizer(),\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification des documents `money-fx`\n",
    "\n",
    "\n",
    "Nous pouvons constater que la mise en minuscule améliore le résultat lorsque la lémmatisation est active. Le fait que la lémmatisation soit active ou non, ne change presque pas les scores. Pour finir la suppression des stopwords améliore systématiquement les scores.\n",
    "\n",
    "\n",
    "TODO Comment results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding best classifier for money-fx\n",
      "----------\n",
      "Accuracy using \"To lower: no, Lemmatize: no, No stopwords: no\": 87.72%\n",
      "Accuracy using \"To lower: yes, Lemmatize: no, No stopwords: no\": 88.74%\n",
      "Accuracy using \"To lower: no, Lemmatize: yes, No stopwords: no\": 87.86%\n",
      "Accuracy using \"To lower: no, Lemmatize: no, No stopwords: yes\": 90.73%\n",
      "Accuracy using \"To lower: yes, Lemmatize: no, No stopwords: yes\": 90.55%\n",
      "Accuracy using \"To lower: no, Lemmatize: yes, No stopwords: yes\": 90.64%\n",
      "Accuracy using \"To lower: yes, Lemmatize: yes, No stopwords: no\": 87.53%\n",
      "Accuracy using \"To lower: yes, Lemmatize: yes, No stopwords: yes\": 91.71%\n"
     ]
    }
   ],
   "source": [
    "classifier_moneyfx, moneyfx_testset = best_classifier(documents, 'money-fx', create_dataset, hyperparams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification des documents `wheat`\n",
    "TODO Comment results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding best classifier for wheat\n",
      "----------\n",
      "Accuracy using \"To lower: no, Lemmatize: no, No stopwords: no\": 89.99%\n",
      "Accuracy using \"To lower: yes, Lemmatize: no, No stopwords: no\": 89.76%\n",
      "Accuracy using \"To lower: no, Lemmatize: yes, No stopwords: no\": 89.99%\n",
      "Accuracy using \"To lower: no, Lemmatize: no, No stopwords: yes\": 93.51%\n",
      "Accuracy using \"To lower: yes, Lemmatize: no, No stopwords: yes\": 94.86%\n",
      "Accuracy using \"To lower: no, Lemmatize: yes, No stopwords: yes\": 93.23%\n",
      "Accuracy using \"To lower: yes, Lemmatize: yes, No stopwords: no\": 90.59%\n",
      "Accuracy using \"To lower: yes, Lemmatize: yes, No stopwords: yes\": 94.35%\n"
     ]
    }
   ],
   "source": [
    "classifier_wheat, wheat_testset = best_classifier(documents, 'wheat', create_dataset, hyperparams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification des documents `gold`\n",
    "TODO Comment results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding best classifier for gold\n",
      "----------\n",
      "Accuracy using \"To lower: no, Lemmatize: no, No stopwords: no\": 93.79%\n",
      "Accuracy using \"To lower: yes, Lemmatize: no, No stopwords: no\": 95.09%\n",
      "Accuracy using \"To lower: no, Lemmatize: yes, No stopwords: no\": 96.71%\n",
      "Accuracy using \"To lower: no, Lemmatize: no, No stopwords: yes\": 98.75%\n",
      "Accuracy using \"To lower: yes, Lemmatize: no, No stopwords: yes\": 98.42%\n",
      "Accuracy using \"To lower: no, Lemmatize: yes, No stopwords: yes\": 98.05%\n",
      "Accuracy using \"To lower: yes, Lemmatize: yes, No stopwords: no\": 98.19%\n",
      "Accuracy using \"To lower: yes, Lemmatize: yes, No stopwords: yes\": 98.56%\n"
     ]
    }
   ],
   "source": [
    "classifier_gold, gold_testset = best_classifier(documents, 'gold', create_dataset, hyperparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ref_test_sets(testset, classifier):\n",
    "    refsets = collections.defaultdict(set)\n",
    "    testsets = collections.defaultdict(set)\n",
    "\n",
    "    for i, (feats, label) in enumerate(testset):\n",
    "        refsets[label].add(i)\n",
    "        observed = classifier.classify(feats)\n",
    "        testsets[observed].add(i)\n",
    "\n",
    "    return refsets, testsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "moneyfx_refsets, moneyfx_testsets = ref_test_sets(moneyfx_testset, classifier_moneyfx)\n",
    "wheat_refsets, wheat_testsets = ref_test_sets(wheat_testset, classifier_wheat)\n",
    "gold_refsets, gold_testsets = ref_test_sets(gold_testset, classifier_gold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Money-fx:\n",
      "---------\n",
      "Precision: 0.3639344262295082\n",
      "Recall: 0.8283582089552238\n",
      "F-mesure: 0.5056947608200456\n",
      "\n",
      "Wheat:\n",
      "---------\n",
      "Precision: 0.32098765432098764\n",
      "Recall: 0.9285714285714286\n",
      "F-mesure: 0.4770642201834862\n",
      "\n",
      "Gold:\n",
      "---------\n",
      "Precision: 0.5306122448979592\n",
      "Recall: 0.896551724137931\n",
      "F-mesure: 0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "print('Money-fx:')\n",
    "print('---------')\n",
    "print('Precision:', precision(moneyfx_refsets[True], moneyfx_testsets[True]))\n",
    "print('Recall:'   , recall(moneyfx_refsets[True], moneyfx_testsets[True]))\n",
    "print('F-mesure:' , f_measure(moneyfx_refsets[True], moneyfx_testsets[True]))\n",
    "\n",
    "print()\n",
    "\n",
    "print('Wheat:')\n",
    "print('---------')\n",
    "print('Precision:', precision(wheat_refsets[True], wheat_testsets[True]))\n",
    "print('Recall:'   , recall(wheat_refsets[True], wheat_testsets[True]))\n",
    "print('F-mesure:' , f_measure(wheat_refsets[True], wheat_testsets[True]))\n",
    "\n",
    "print()\n",
    "\n",
    "print('Gold:')\n",
    "print('---------')\n",
    "print('Precision:', precision(gold_refsets[True], gold_testsets[True]))\n",
    "print('Recall:'   , recall(gold_refsets[True], gold_testsets[True]))\n",
    "print('F-mesure:' , f_measure(gold_refsets[True], gold_testsets[True]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifieur multiclasse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_multi_dataset(documents, tags, feature_extractor, **kwargs):\n",
    "    if 'to_lower' in kwargs and kwargs['to_lower']:\n",
    "        documents = list(map(lambda d: (list(map(str.lower, d[0])), d[1]), documents))\n",
    "\n",
    "    if 'lemmatizer' in kwargs:\n",
    "        lemmatizer = kwargs['lemmatizer']\n",
    "        documents = list(map(lambda d: (list(map(lemmatizer.lemmatize, d[0])), d[1]), documents))\n",
    "    \n",
    "    if 'stopwords' in kwargs:\n",
    "        stopwords = set(kwargs['stopwords'])\n",
    "        documents = list(map(\n",
    "            lambda d: (\n",
    "                list(filter(lambda w: not w.lower() in stopwords and w[0].isalnum(), d[0])), \n",
    "                d[1]\n",
    "            ), documents))\n",
    "        \n",
    "    analyzer_res = []\n",
    "    if 'analyzer' in kwargs:\n",
    "        analyzer_res = kwargs['analyzer'](documents)\n",
    "\n",
    "    dataset = []\n",
    "    for document in documents:\n",
    "        document_tags = list(set(tags).intersection(document[1]))\n",
    "        tag = 'other' if document_tags == [] else document_tags[0]\n",
    "\n",
    "        dataset.append((feature_extractor(document[0], analyzer_res), tag))\n",
    "    \n",
    "    shuffle(dataset)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_multi_classifier(documents, tag, hyperparams):\n",
    "    print('Finding best milti-classifier for {}'.format(tag))\n",
    "    print('----------')\n",
    "\n",
    "    best = (None, 0.0)\n",
    "    for hyperparam in hyperparams:\n",
    "        dataset = create_multi_dataset(documents, tag, **hyperparam)\n",
    "        train_set, test_set, dev_set = split_dataset(dataset)\n",
    "        classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "        acc = nltk.classify.accuracy(classifier, dev_set)\n",
    "        \n",
    "        if acc > best[1]:\n",
    "            best = (classifier, acc)\n",
    "        \n",
    "        print('Accuracy using \"{}\": {:.2f}%'.format(hyperparam['title'], acc*100))\n",
    "    return (best[0], test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tags = ['money-fx', 'wheat', 'gold']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparams = [\n",
    "    {\n",
    "        'title': 'To lower: no, Lemmatize: no, No stopwords: no',\n",
    "        'feature_extractor': document_features,\n",
    "        'analyzer': most_freq_words,\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding best classifier for ['money-fx', 'wheat', 'gold']\n",
      "----------\n",
      "Accuracy using \"To lower: no, Lemmatize: no, No stopwords: no\": 81.42%\n",
      "Accuracy using \"To lower: yes, Lemmatize: no, No stopwords: no\": 79.84%\n",
      "Accuracy using \"To lower: no, Lemmatize: yes, No stopwords: no\": 80.82%\n",
      "Accuracy using \"To lower: no, Lemmatize: no, No stopwords: yes\": 84.43%\n",
      "Accuracy using \"To lower: yes, Lemmatize: no, No stopwords: yes\": 87.63%\n",
      "Accuracy using \"To lower: no, Lemmatize: yes, No stopwords: yes\": 85.77%\n",
      "Accuracy using \"To lower: yes, Lemmatize: yes, No stopwords: no\": 81.09%\n",
      "Accuracy using \"To lower: yes, Lemmatize: yes, No stopwords: yes\": 86.14%\n"
     ]
    }
   ],
   "source": [
    "classifier_multi, multi_testset = best_multi_classifier(documents, tags, hyperparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_refsets, multi_testsets = ref_test_sets(multi_testset, classifier_multi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for multiclass classifiers for Money-Fx, Wheat, Gold\n",
      "\n",
      "Money-Fx:\n",
      "---------\n",
      "Precision: 0.41522491349480967\n",
      "Recall: 0.8\n",
      "F-mesure: 0.5466970387243735\n",
      "\n",
      "Wheat:\n",
      "---------\n",
      "Precision: 0.33544303797468356\n",
      "Recall: 0.9298245614035088\n",
      "F-mesure: 0.4930232558139535\n",
      "\n",
      "Gold:\n",
      "---------\n",
      "Precision: 0.5483870967741935\n",
      "Recall: 0.85\n",
      "F-mesure: 0.6666666666666666\n",
      "\n",
      "Other:\n",
      "---------\n",
      "Precision: 0.9797619047619047\n",
      "Recall: 0.8524080787156914\n",
      "F-mesure: 0.911658820271393\n"
     ]
    }
   ],
   "source": [
    "words = tags[:]\n",
    "print(\"Score for multiclass classifiers for {}\".format(\", \".join(map(lambda i: i.title(), words))))\n",
    "words.append('other')\n",
    "for word in words:\n",
    "    print(\"\")\n",
    "    print('{}:'.format(word.title()))\n",
    "    print('---------')\n",
    "    print('Precision:', precision(multi_refsets[word], multi_testsets[word]))\n",
    "    print('Recall:'   , recall(multi_refsets[word], multi_testsets[word]))\n",
    "    print('F-mesure:' , f_measure(multi_refsets[word], multi_testsets[word]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for *mono* class classifiers\n",
      "\n",
      "Money-fx:\n",
      "---------\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'moneyfx_refsets' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-2b902c2791c7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Money-fx:'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'---------'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Precision:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecision\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmoneyfx_refsets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmoneyfx_testsets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Recall:'\u001b[0m   \u001b[0;34m,\u001b[0m \u001b[0mrecall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmoneyfx_refsets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmoneyfx_testsets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'F-mesure:'\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mf_measure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmoneyfx_refsets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmoneyfx_testsets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'moneyfx_refsets' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"Score for *mono*class classifiers\")\n",
    "\n",
    "print()\n",
    "\n",
    "print('Money-fx:')\n",
    "print('---------')\n",
    "print('Precision:', precision(moneyfx_refsets[True], moneyfx_testsets[True]))\n",
    "print('Recall:'   , recall(moneyfx_refsets[True], moneyfx_testsets[True]))\n",
    "print('F-mesure:' , f_measure(moneyfx_refsets[True], moneyfx_testsets[True]))\n",
    "\n",
    "print()\n",
    "\n",
    "print('Wheat:')\n",
    "print('---------')\n",
    "print('Precision:', precision(wheat_refsets[True], wheat_testsets[True]))\n",
    "print('Recall:'   , recall(wheat_refsets[True], wheat_testsets[True]))\n",
    "print('F-mesure:' , f_measure(wheat_refsets[True], wheat_testsets[True]))\n",
    "\n",
    "print()\n",
    "\n",
    "print('Gold:')\n",
    "print('---------')\n",
    "print('Precision:', precision(gold_refsets[True], gold_testsets[True]))\n",
    "print('Recall:'   , recall(gold_refsets[True], gold_testsets[True]))\n",
    "print('F-mesure:' , f_measure(gold_refsets[True], gold_testsets[True]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# micro / macro average?\n",
    "# calculate precision, recall & f-score for each tag in multi class\n",
    "# compare result with corresponding binary classifier"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
