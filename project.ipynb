{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "spanish-copyright",
   "metadata": {},
   "source": [
    "# TAL - Classification de dépêches d’agence avec NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "focal-herald",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing modules\n",
    "import nltk\n",
    "import string\n",
    "import collections\n",
    "\n",
    "from nltk.corpus import reuters\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.metrics.scores import (precision, recall, f_measure)\n",
    "\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "tracked-amazon",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['NORTH', 'EAST', '&', 'lt', ';', 'NEIC', '>', 'MAY', ...], ['earn'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract fileids from the reuters corpus\n",
    "fileids = reuters.fileids()\n",
    "documents = []\n",
    "# Loop through each file id and collect each files categories and tokenized words\n",
    "for file in fileids:\n",
    "    words = reuters.words(file)\n",
    "    documents.append((words, reuters.categories(file)))\n",
    "\n",
    "shuffle(documents)\n",
    "documents[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opposite-superior",
   "metadata": {},
   "source": [
    "Nous avons remarqué que dans la tokenisation des mots du corpus, le mots `U.S` est séparé en trois tokens distinct, `U`, `.` et `S`. Nous avon estimé que dans le cadre de ce labo, cela ne devrait pas causer trop de problèmes et nous avons donc laissé cette séparation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pharmaceutical-heritage",
   "metadata": {},
   "source": [
    "## Classifieur binaire\n",
    "\n",
    "Pour la classification des documents, nous avons décidé d'utiliser la fréquence des mots. Nous avons donc commencé par déterminer la fréquence de **TOUT** les mots du dataset (i.e. tout les documents), puis les `2000` mots les plus fréquents sont retourné.\n",
    "\n",
    "> Note: La limite de la fréquence des mots que la fonction retourne est paramètrable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bound-delaware",
   "metadata": {},
   "outputs": [],
   "source": [
    "def document_features(document, word_frequence):\n",
    "    document_words = set(document)\n",
    "    features = {}\n",
    "    for word in word_frequence:\n",
    "        features['contains({})'.format(word)] = (word in document_words)\n",
    "    return features\n",
    "\n",
    "def most_freq_words(documents, limit=2000):\n",
    "    all_words = nltk.FreqDist(w\n",
    "        for document in documents\n",
    "        for w in document[0]\n",
    "    )\n",
    "    return list(all_words)[:limit]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fitting-terrorism",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(documents, tag, feature_extractor, **kwargs):\n",
    "    if 'to_lower' in kwargs and kwargs['to_lower']:\n",
    "        documents = list(map(lambda d: (list(map(str.lower, d[0])), d[1]), documents))\n",
    "\n",
    "    if 'lemmatizer' in kwargs:\n",
    "        lemmatizer = kwargs['lemmatizer']\n",
    "        documents = list(map(lambda d: (list(map(lemmatizer.lemmatize, d[0])), d[1]), documents))\n",
    "    \n",
    "    if 'stopwords' in kwargs:\n",
    "        stopwords = set(kwargs['stopwords'])\n",
    "        documents = list(map(\n",
    "            lambda d: (\n",
    "                list(filter(lambda w: not w.lower() in stopwords and w[0].isalnum(), d[0])), \n",
    "                d[1]\n",
    "            ), documents))\n",
    "        \n",
    "    analyzer_res = []\n",
    "    if 'analyzer' in kwargs:\n",
    "        analyzer_res = kwargs['analyzer'](documents)\n",
    "\n",
    "    dataset = []\n",
    "    for document in documents:\n",
    "        dataset.append((feature_extractor(document[0], analyzer_res), tag in document[1]))\n",
    "    \n",
    "    shuffle(dataset)\n",
    "    return dataset\n",
    "\n",
    "def split_dataset(dataset):\n",
    "    split_ratio = 0.6\n",
    "    split_ratio2 = 0.8\n",
    "    \n",
    "    split = int(len(dataset) * split_ratio)\n",
    "    split2 = int(len(dataset) * split_ratio2)\n",
    "\n",
    "    return (dataset[:split], dataset[split:split2], dataset[split2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "operating-specialist",
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_classifier(documents, tag, dataset_creator, hyperparams):\n",
    "    print('Finding best classifier for {}'.format(tag))\n",
    "    print('----------')\n",
    "\n",
    "    best = (None, 0.0)\n",
    "    for hyperparam in hyperparams:\n",
    "        dataset = dataset_creator(documents, tag, **hyperparam)\n",
    "        train_set, test_set, dev_set = split_dataset(dataset)\n",
    "        classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "        acc = nltk.classify.accuracy(classifier, dev_set)\n",
    "        \n",
    "        if acc > best[1]:\n",
    "            best = (classifier, acc)\n",
    "        \n",
    "        print('Accuracy using \"{}\": {:.2f}%'.format(hyperparam['title'], acc*100))\n",
    "    return (best[0], test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "numerous-disability",
   "metadata": {},
   "source": [
    "### Combinaison des différents hyperparamètres\n",
    "\n",
    "Pour les hyperparamètres, nous avons choisi d'utiliser de supprimer les stopwords, la lemmatisation et de tout mettre en minuscules. En plus de tester chaque hyperparamètre indépendamment, nous avons aussi testé d'appliquer plusieurs hyperparamètre en même temps (e.g. lemmatiser et supprimer les stopwords)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dried-coating",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparams = [\n",
    "    {\n",
    "        'title': 'To lower: no, Lemmatize: no, No stopwords: no',\n",
    "        'feature_extractor': document_features,\n",
    "        'analyzer': most_freq_words,\n",
    "    },\n",
    "    {\n",
    "        'title': 'To lower: yes, Lemmatize: no, No stopwords: no',\n",
    "        'feature_extractor': document_features,\n",
    "        'analyzer': most_freq_words,\n",
    "        'to_lower': True,\n",
    "    },\n",
    "    {\n",
    "        'title': 'To lower: no, Lemmatize: yes, No stopwords: no',\n",
    "        'feature_extractor': document_features,\n",
    "        'analyzer': most_freq_words,\n",
    "        'lemmatizer': WordNetLemmatizer(),\n",
    "    },\n",
    "    {\n",
    "        'title': 'To lower: no, Lemmatize: no, No stopwords: yes',\n",
    "        'feature_extractor': document_features,\n",
    "        'analyzer': most_freq_words,\n",
    "        'stopwords': stopwords.words('english'),\n",
    "    },\n",
    "    {\n",
    "        'title': 'To lower: yes, Lemmatize: no, No stopwords: yes',\n",
    "        'feature_extractor': document_features,\n",
    "        'analyzer': most_freq_words,\n",
    "        'to_lower': True,\n",
    "        'stopwords': stopwords.words('english'),\n",
    "    },\n",
    "    {\n",
    "        'title': 'To lower: no, Lemmatize: yes, No stopwords: yes',\n",
    "        'feature_extractor': document_features,\n",
    "        'analyzer': most_freq_words,\n",
    "        'lemmatizer': WordNetLemmatizer(),\n",
    "        'stopwords': stopwords.words('english'),\n",
    "    },\n",
    "    {\n",
    "        'title': 'To lower: yes, Lemmatize: yes, No stopwords: no',\n",
    "        'feature_extractor': document_features,\n",
    "        'analyzer': most_freq_words,\n",
    "        'to_lower': True,\n",
    "        'lemmatizer': WordNetLemmatizer(),\n",
    "    },\n",
    "    {\n",
    "        'title': 'To lower: yes, Lemmatize: yes, No stopwords: yes',\n",
    "        'feature_extractor': document_features,\n",
    "        'analyzer': most_freq_words,\n",
    "        'to_lower': True,\n",
    "        'stopwords': stopwords.words('english'),\n",
    "        'lemmatizer': WordNetLemmatizer(),\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "static-criminal",
   "metadata": {},
   "source": [
    "### Classification des documents `money-fx`\n",
    "\n",
    "Si l'on compare chaque hyperparamètres seul, on peut voir que la mise en minuscule est légèrement meilleur que les autres. Le fait de combiner la mise en minuscule avec les autres hyperparamètres améliore les scores. Et finalement, on remarque que combiner les trois hyperparamètres améliore le score (accuracy) du classifieur d'environ 3%.\n",
    "\n",
    ">Résultats lors de l'écriture des commentaires:\n",
    ">\n",
    ">```\n",
    ">Finding best classifier for money-fx\n",
    ">----------\n",
    ">Accuracy using \"To lower: no, Lemmatize: no, No stopwords: no\": 87.72%\n",
    ">Accuracy using \"To lower: yes, Lemmatize: no, No stopwords: no\": 88.74%\n",
    ">Accuracy using \"To lower: no, Lemmatize: yes, No stopwords: no\": 87.86%\n",
    ">Accuracy using \"To lower: no, Lemmatize: no, No stopwords: yes\": 90.73%\n",
    ">Accuracy using \"To lower: yes, Lemmatize: no, No stopwords: yes\": 90.55%\n",
    ">Accuracy using \"To lower: no, Lemmatize: yes, No stopwords: yes\": 90.64%\n",
    ">Accuracy using \"To lower: yes, Lemmatize: yes, No stopwords: no\": 87.53%\n",
    ">Accuracy using \"To lower: yes, Lemmatize: yes, No stopwords: yes\": 91.71%\n",
    ">```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "authorized-louisiana",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding best classifier for money-fx\n",
      "----------\n",
      "Accuracy using \"To lower: no, Lemmatize: no, No stopwords: no\": 87.72%\n",
      "Accuracy using \"To lower: yes, Lemmatize: no, No stopwords: no\": 88.74%\n",
      "Accuracy using \"To lower: no, Lemmatize: yes, No stopwords: no\": 87.86%\n",
      "Accuracy using \"To lower: no, Lemmatize: no, No stopwords: yes\": 90.73%\n",
      "Accuracy using \"To lower: yes, Lemmatize: no, No stopwords: yes\": 90.55%\n",
      "Accuracy using \"To lower: no, Lemmatize: yes, No stopwords: yes\": 90.64%\n",
      "Accuracy using \"To lower: yes, Lemmatize: yes, No stopwords: no\": 87.53%\n",
      "Accuracy using \"To lower: yes, Lemmatize: yes, No stopwords: yes\": 91.71%\n"
     ]
    }
   ],
   "source": [
    "classifier_moneyfx, moneyfx_testset = best_classifier(documents, 'money-fx', create_dataset, hyperparams)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "industrial-mechanism",
   "metadata": {},
   "source": [
    "### Classification des documents `wheat`\n",
    "\n",
    "Si l'on compare chaque hyperparamètres seul, on peut voir que cette fois, c'est la suppression des stopwords est meilleur que les autres. Le fait de combiner la suppression des stopwords avec les autres hyperparamètres améliore les scores. Et finalement, on remarque que combiner les trois hyperparamètres améliore le score (accuracy) du classifieur, mais qu'il n'est pas le meilleur (comme pour le classifieur `money-fx`). Ici le meilleur classifieur est celui qui combine la supression des stopwords et la mise en minuscule.\n",
    "\n",
    ">Résultats lors de l'écriture des commentaires:\n",
    ">\n",
    ">```\n",
    ">Finding best classifier for money-fx\n",
    ">----------\n",
    ">Accuracy using \"To lower: no, Lemmatize: no, No stopwords: no\": 89.99%\n",
    ">Accuracy using \"To lower: yes, Lemmatize: no, No stopwords: no\": 89.76%\n",
    ">Accuracy using \"To lower: no, Lemmatize: yes, No stopwords: no\": 89.99%\n",
    ">Accuracy using \"To lower: no, Lemmatize: no, No stopwords: yes\": 93.51%\n",
    ">Accuracy using \"To lower: yes, Lemmatize: no, No stopwords: yes\": 94.86%\n",
    ">Accuracy using \"To lower: no, Lemmatize: yes, No stopwords: yes\": 93.23%\n",
    ">Accuracy using \"To lower: yes, Lemmatize: yes, No stopwords: no\": 90.59%\n",
    ">Accuracy using \"To lower: yes, Lemmatize: yes, No stopwords: yes\": 94.35%\n",
    ">```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "driven-professional",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding best classifier for wheat\n",
      "----------\n",
      "Accuracy using \"To lower: no, Lemmatize: no, No stopwords: no\": 89.99%\n",
      "Accuracy using \"To lower: yes, Lemmatize: no, No stopwords: no\": 89.76%\n",
      "Accuracy using \"To lower: no, Lemmatize: yes, No stopwords: no\": 89.99%\n",
      "Accuracy using \"To lower: no, Lemmatize: no, No stopwords: yes\": 93.51%\n",
      "Accuracy using \"To lower: yes, Lemmatize: no, No stopwords: yes\": 94.86%\n",
      "Accuracy using \"To lower: no, Lemmatize: yes, No stopwords: yes\": 93.23%\n",
      "Accuracy using \"To lower: yes, Lemmatize: yes, No stopwords: no\": 90.59%\n",
      "Accuracy using \"To lower: yes, Lemmatize: yes, No stopwords: yes\": 94.35%\n"
     ]
    }
   ],
   "source": [
    "classifier_wheat, wheat_testset = best_classifier(documents, 'wheat', create_dataset, hyperparams)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "polish-function",
   "metadata": {},
   "source": [
    "### Classification des documents `gold`\n",
    "\n",
    "Pour ce classifieur nous nous retrouvons plus ou moins dans la même situation que le classifieur `wheat`. C'est-à-dire que le meilleur classifieur avec un seul hyperparamètre et aussi celui qui supprime les stopwords. Sauf que quand nous combinons les hyperparamètre, il y a certes une amélioration des classifieurs qui utilise les deux autres hyperparamètres **mais**, aucune combinaison n'est meilleur que le classifieur avec seulement la suppression des stopwords.\n",
    "\n",
    ">Résultats lors de l'écriture des commentaires:\n",
    ">\n",
    ">```\n",
    ">Finding best classifier for money-fx\n",
    ">----------\n",
    ">Accuracy using \"To lower: no, Lemmatize: no, No stopwords: no\": 93.79%\n",
    ">Accuracy using \"To lower: yes, Lemmatize: no, No stopwords: no\": 95.09%\n",
    ">Accuracy using \"To lower: no, Lemmatize: yes, No stopwords: no\": 96.71%\n",
    ">Accuracy using \"To lower: no, Lemmatize: no, No stopwords: yes\": 98.75%\n",
    ">Accuracy using \"To lower: yes, Lemmatize: no, No stopwords: yes\": 98.42%\n",
    ">Accuracy using \"To lower: no, Lemmatize: yes, No stopwords: yes\": 98.05%\n",
    ">Accuracy using \"To lower: yes, Lemmatize: yes, No stopwords: no\": 98.19%\n",
    ">Accuracy using \"To lower: yes, Lemmatize: yes, No stopwords: yes\": 98.56%\n",
    ">```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "organized-scene",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding best classifier for gold\n",
      "----------\n",
      "Accuracy using \"To lower: no, Lemmatize: no, No stopwords: no\": 93.79%\n",
      "Accuracy using \"To lower: yes, Lemmatize: no, No stopwords: no\": 95.09%\n",
      "Accuracy using \"To lower: no, Lemmatize: yes, No stopwords: no\": 96.71%\n",
      "Accuracy using \"To lower: no, Lemmatize: no, No stopwords: yes\": 98.75%\n",
      "Accuracy using \"To lower: yes, Lemmatize: no, No stopwords: yes\": 98.42%\n",
      "Accuracy using \"To lower: no, Lemmatize: yes, No stopwords: yes\": 98.05%\n",
      "Accuracy using \"To lower: yes, Lemmatize: yes, No stopwords: no\": 98.19%\n",
      "Accuracy using \"To lower: yes, Lemmatize: yes, No stopwords: yes\": 98.56%\n"
     ]
    }
   ],
   "source": [
    "classifier_gold, gold_testset = best_classifier(documents, 'gold', create_dataset, hyperparams)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "potential-shareware",
   "metadata": {},
   "source": [
    "Si l'on compare les trois classifieurs n'utilise pas les même hyperparamètres, mais l'on remarque que le classifieur `money-fx` est moins bon que les deux autres. Nous avons comparé la taille des datasets et nous avons remarqué que celui pour `money-fx` est beaucoup plus grands que les deux autres (717 `money-fx` 283 `wheat` et 124 `gold`). Cette différence en taille explique la différence de qualité dans les classifieurs, étant donnée que les classifeurs `wheat` et `gold` on des dataset plus petit il y a une plus grande chance que les documents de leur dataset contienne les mots les plus fréquents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "white-filing",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ref_test_sets(testset, classifier):\n",
    "    refsets = collections.defaultdict(set)\n",
    "    testsets = collections.defaultdict(set)\n",
    "\n",
    "    for i, (feats, label) in enumerate(testset):\n",
    "        refsets[label].add(i)\n",
    "        observed = classifier.classify(feats)\n",
    "        testsets[observed].add(i)\n",
    "\n",
    "    return refsets, testsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "median-athletics",
   "metadata": {},
   "outputs": [],
   "source": [
    "moneyfx_refsets, moneyfx_testsets = ref_test_sets(moneyfx_testset, classifier_moneyfx)\n",
    "wheat_refsets, wheat_testsets = ref_test_sets(wheat_testset, classifier_wheat)\n",
    "gold_refsets, gold_testsets = ref_test_sets(gold_testset, classifier_gold)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "composite-insured",
   "metadata": {},
   "source": [
    "En regardant la précision, le rappel et la F-Mesure de tout nos classifieurs, on remarque qu'ils ne sont pas précis du tout. C'est-à-dire qu'il n'arrive pas à correctement classifier les documents du type que l'on souhaite classifier. Par contre, si l'on regarde le rappel, on voit qu'ils ont tous de très bon score (> 80%), ce qui veut dire qu'ils sont capables de bien classifier les documents qui ne sont pas ceux que l'on souhaite classifier. Cette différence drastique est normale, car nous avons une distribution qui n'est pas bien répartie (i.e. il y a plus de documents qui ne font pas parti de la classe). Et donc pour vraiment évaluer la qualité de notre classifieur, il faut regarder le F-Mesure. Et là, on voit que nos classifieurs ont un score d'environ 50%, ce qui veut dire qu'ils sont bof.\n",
    "\n",
    ">Résultats lors de l'écriture des commentaires:\n",
    ">\n",
    ">```\n",
    ">Money-fx:\n",
    ">---------\n",
    ">Precision: 0.3639344262295082\n",
    ">Recall: 0.8283582089552238\n",
    ">F-mesure: 0.5056947608200456\n",
    ">\n",
    ">Wheat:\n",
    ">---------\n",
    ">Precision: 0.32098765432098764\n",
    ">Recall: 0.9285714285714286\n",
    ">F-mesure: 0.4770642201834862\n",
    ">\n",
    ">Gold:\n",
    ">---------\n",
    ">Precision: 0.5306122448979592\n",
    ">Recall: 0.896551724137931\n",
    ">F-mesure: 0.6666666666666666\n",
    ">```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "corresponding-category",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Money-fx:\n",
      "---------\n",
      "Precision: 0.3639344262295082\n",
      "Recall: 0.8283582089552238\n",
      "F-mesure: 0.5056947608200456\n",
      "\n",
      "Wheat:\n",
      "---------\n",
      "Precision: 0.32098765432098764\n",
      "Recall: 0.9285714285714286\n",
      "F-mesure: 0.4770642201834862\n",
      "\n",
      "Gold:\n",
      "---------\n",
      "Precision: 0.5306122448979592\n",
      "Recall: 0.896551724137931\n",
      "F-mesure: 0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "print('Money-fx:')\n",
    "print('---------')\n",
    "print('Precision:', precision(moneyfx_refsets[True], moneyfx_testsets[True]))\n",
    "print('Recall:'   , recall(moneyfx_refsets[True], moneyfx_testsets[True]))\n",
    "print('F-mesure:' , f_measure(moneyfx_refsets[True], moneyfx_testsets[True]))\n",
    "\n",
    "print()\n",
    "\n",
    "print('Wheat:')\n",
    "print('---------')\n",
    "print('Precision:', precision(wheat_refsets[True], wheat_testsets[True]))\n",
    "print('Recall:'   , recall(wheat_refsets[True], wheat_testsets[True]))\n",
    "print('F-mesure:' , f_measure(wheat_refsets[True], wheat_testsets[True]))\n",
    "\n",
    "print()\n",
    "\n",
    "print('Gold:')\n",
    "print('---------')\n",
    "print('Precision:', precision(gold_refsets[True], gold_testsets[True]))\n",
    "print('Recall:'   , recall(gold_refsets[True], gold_testsets[True]))\n",
    "print('F-mesure:' , f_measure(gold_refsets[True], gold_testsets[True]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "whole-salad",
   "metadata": {},
   "source": [
    "## Classifieur multiclasse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "lyric-three",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_multi_dataset(documents, tags, feature_extractor, **kwargs):\n",
    "    if 'to_lower' in kwargs and kwargs['to_lower']:\n",
    "        documents = list(map(lambda d: (list(map(str.lower, d[0])), d[1]), documents))\n",
    "\n",
    "    if 'lemmatizer' in kwargs:\n",
    "        lemmatizer = kwargs['lemmatizer']\n",
    "        documents = list(map(lambda d: (list(map(lemmatizer.lemmatize, d[0])), d[1]), documents))\n",
    "    \n",
    "    if 'stopwords' in kwargs:\n",
    "        stopwords = set(kwargs['stopwords'])\n",
    "        documents = list(map(\n",
    "            lambda d: (\n",
    "                list(filter(lambda w: not w.lower() in stopwords and w[0].isalnum(), d[0])), \n",
    "                d[1]\n",
    "            ), documents))\n",
    "        \n",
    "    analyzer_res = []\n",
    "    if 'analyzer' in kwargs:\n",
    "        analyzer_res = kwargs['analyzer'](documents)\n",
    "\n",
    "    dataset = []\n",
    "    for document in documents:\n",
    "        document_tags = list(set(tags).intersection(document[1]))\n",
    "        tag = 'other' if document_tags == [] else document_tags[0]\n",
    "\n",
    "        dataset.append((feature_extractor(document[0], analyzer_res), tag))\n",
    "    \n",
    "    shuffle(dataset)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "younger-headquarters",
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_multi_classifier(documents, tag, hyperparams):\n",
    "    print('Finding best milti-classifier for {}'.format(tag))\n",
    "    print('----------')\n",
    "\n",
    "    best = (None, 0.0)\n",
    "    for hyperparam in hyperparams:\n",
    "        dataset = create_multi_dataset(documents, tag, **hyperparam)\n",
    "        train_set, test_set, dev_set = split_dataset(dataset)\n",
    "        classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "        acc = nltk.classify.accuracy(classifier, dev_set)\n",
    "        \n",
    "        if acc > best[1]:\n",
    "            best = (classifier, acc)\n",
    "        \n",
    "        print('Accuracy using \"{}\": {:.2f}%'.format(hyperparam['title'], acc*100))\n",
    "    return (best[0], test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spatial-alpha",
   "metadata": {},
   "source": [
    "### Classification des documents pour `money-fx`, `wheat` et `gold`\n",
    "Réutilisation des hyperparamètre utilisé dans la partie sur les classifiers binaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "recorded-madrid",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tags = ['money-fx', 'wheat', 'gold']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "outside-census",
   "metadata": {},
   "source": [
    "Nous pouvons constater que le fait de mettre en minuscule améliore systématiquement le score.\n",
    "La suppression des stopwords améliore notablement les résultats. La lémmatisation ne change pas grand chose aux scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "impressive-compiler",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding best classifier for ['money-fx', 'wheat', 'gold']\n",
      "----------\n",
      "Accuracy using \"To lower: no, Lemmatize: no, No stopwords: no\": 81.42%\n",
      "Accuracy using \"To lower: yes, Lemmatize: no, No stopwords: no\": 79.84%\n",
      "Accuracy using \"To lower: no, Lemmatize: yes, No stopwords: no\": 80.82%\n",
      "Accuracy using \"To lower: no, Lemmatize: no, No stopwords: yes\": 84.43%\n",
      "Accuracy using \"To lower: yes, Lemmatize: no, No stopwords: yes\": 87.63%\n",
      "Accuracy using \"To lower: no, Lemmatize: yes, No stopwords: yes\": 85.77%\n",
      "Accuracy using \"To lower: yes, Lemmatize: yes, No stopwords: no\": 81.09%\n",
      "Accuracy using \"To lower: yes, Lemmatize: yes, No stopwords: yes\": 86.14%\n"
     ]
    }
   ],
   "source": [
    "classifier_multi, multi_testset = best_multi_classifier(documents, tags, hyperparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "equivalent-poetry",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_refsets, multi_testsets = ref_test_sets(multi_testset, classifier_multi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fantastic-tradition",
   "metadata": {},
   "source": [
    "### Precision, recall et F-mesure\n",
    "\n",
    "Nous constatons que la precision est meilleures pour le classifiers multi-class, mais le recall est identique ou inférieur. Cependant la F1 mesure est systèmatiquement meilleur pour le multi-class.\n",
    "\n",
    "\n",
    "| | | precision | recall | F1 | \n",
    "| :--- | :--- | --- | --- | --- | \n",
    "| Multi-class | Money-fx | 41.52% | 80.00% | 54.66% |\n",
    "| Multi-class | Wheat    | 33.54% | 92.98% | 49.30% |\n",
    "| Multi-class | Gold     | 54.83% | 85.00% | 66.66% |\n",
    "| Binaire     | Money-fx | 36.39% | 82.83% | 50.56% |\n",
    "| Binaire     | Wheat    | 32.09% | 92.85% | 47.70% |\n",
    "| Binaire     | Gold     | 53.06% | 89.65% | 66.66% |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eastern-leadership",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for multiclass classifiers for Money-Fx, Wheat, Gold\n",
      "\n",
      "Money-Fx:\n",
      "---------\n",
      "Precision: 0.41522491349480967\n",
      "Recall: 0.8\n",
      "F-mesure: 0.5466970387243735\n",
      "\n",
      "Wheat:\n",
      "---------\n",
      "Precision: 0.33544303797468356\n",
      "Recall: 0.9298245614035088\n",
      "F-mesure: 0.4930232558139535\n",
      "\n",
      "Gold:\n",
      "---------\n",
      "Precision: 0.5483870967741935\n",
      "Recall: 0.85\n",
      "F-mesure: 0.6666666666666666\n",
      "\n",
      "Other:\n",
      "---------\n",
      "Precision: 0.9797619047619047\n",
      "Recall: 0.8524080787156914\n",
      "F-mesure: 0.911658820271393\n"
     ]
    }
   ],
   "source": [
    "words = tags[:]\n",
    "print(\"Score for multiclass classifiers for {}\".format(\", \".join(map(lambda i: i.title(), words))))\n",
    "words.append('other')\n",
    "for word in words:\n",
    "    print(\"\")\n",
    "    print('{}:'.format(word.title()))\n",
    "    print('---------')\n",
    "    print('Precision:', precision(multi_refsets[word], multi_testsets[word]))\n",
    "    print('Recall:'   , recall(multi_refsets[word], multi_testsets[word]))\n",
    "    print('F-mesure:' , f_measure(multi_refsets[word], multi_testsets[word]))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
